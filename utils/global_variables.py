import torch


EMOTION_MAPPING = {
    'ECF': {'angry': 0, 'anger': 0,
            'disgust': 1,
            'fear': 2,
            'joy': 3, 'happines': 3, 'happiness': 3, 'excited': 3, 'happy': 3,
            'sad': 4, 'sadness': 4, 'frustrated': 4,
            'surprise': 5, 'surprised': 5, 
            'neutral': 6},
    'MECAD': {'Angry': 0, 'Anger': 0,
            'Disgust': 1,
            'Fear': 2,
            'Joy': 3, 'Happiness': 3, 'Excited': 3, 'Happy': 3,
            'Sad': 4, 'Sadness': 4, 'Frustrated': 4,
            'Surprise': 5, 'Surprised': 5,
            'Neutral': 6},
}

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


GRAPH_CONFIG_T_A_V = {
    'meta_paths' : [
        ['utterance_t', 'same_speaker_t', 'utterance_t'],
        ['utterance_a', 'same_speaker_a', 'utterance_a'],
        ['utterance_v', 'same_speaker_v', 'utterance_v'],
        ['utterance_t', 'same_speaker_t_a', 'utterance_a'],
        ['utterance_t', 'same_speaker_t_v', 'utterance_v'],
        ['utterance_a', 'same_speaker_a_v', 'utterance_v'],
        ['utterance_t', 'different_speaker_t', 'utterance_t'],
        ['utterance_a', 'different_speaker_a', 'utterance_a'],
        ['utterance_v', 'different_speaker_v', 'utterance_v'],
        ['utterance_t', 'different_speaker_t_a', 'utterance_a'],
        ['utterance_t', 'different_speaker_t_v', 'utterance_v'],
        ['utterance_a', 'different_speaker_a_v', 'utterance_v'],
        ['utterance_t', 'global_t', 'conversation_t'],
        ['utterance_a', 'global_a', 'conversation_a'],
        ['utterance_v', 'global_v', 'conversation_v'],
        ['conversation_t', 'global_t', 'utterance_t'],
        ['conversation_a', 'global_a', 'utterance_a'],
        ['conversation_v', 'global_v', 'utterance_v'],
        ['utterance_t', 'emotional_link_t', 'emotion'],
        ['utterance_a', 'emotional_link_a', 'emotion'],
        ['utterance_v', 'emotional_link_v', 'emotion'],
        ['utterance_t', 'causal_link_t', 'cause'],
        ['utterance_a', 'causal_link_a', 'cause'],
        ['utterance_v', 'causal_link_v', 'cause'],
        ['utterance_t', 't_a', 'utterance_a'],
        ['utterance_a', 't_a', 'utterance_t'],
        ['utterance_t', 't_v', 'utterance_v'],
        ['utterance_v', 't_v', 'utterance_t'],
        ['utterance_a', 'a_v', 'utterance_v'],
        ['utterance_v', 'a_v', 'utterance_a'],
        ['conversation_t', 't_a', 'conversation_a'],
        ['conversation_a', 't_a', 'conversation_t'],
        ['conversation_t', 't_v', 'conversation_v'],
        ['conversation_v', 't_v', 'conversation_t'],
        ['conversation_a', 'a_v', 'conversation_v'],
        ['conversation_v', 'a_v', 'conversation_a'],
    ],
    'graph_structure': {
            ('utterance_t', 'global_t', 'conversation_t'): ([], []),
            ('utterance_a', 'global_a', 'conversation_a'): ([], []),
            ('utterance_v', 'global_v', 'conversation_v'): ([], []),
            ('utterance_t', 'same_speaker_t', 'utterance_t'): ([], []),
            ('utterance_a', 'same_speaker_a', 'utterance_a'): ([], []),
            ('utterance_v', 'same_speaker_v', 'utterance_v'): ([], []),
            ('utterance_t', 'same_speaker_t_a', 'utterance_a'): ([], []),
            ('utterance_t', 'same_speaker_t_v', 'utterance_v'): ([], []),
            ('utterance_a', 'same_speaker_a_v', 'utterance_v'): ([], []),
            ('utterance_t', 'different_speaker_t', 'utterance_t'): ([], []),
            ('utterance_a', 'different_speaker_a', 'utterance_a'): ([], []),
            ('utterance_v', 'different_speaker_v', 'utterance_v'): ([], []),
            ('utterance_t', 'different_speaker_t_a', 'utterance_a'): ([], []),
            ('utterance_t', 'different_speaker_t_v', 'utterance_v'): ([], []),
            ('utterance_a', 'different_speaker_a_v', 'utterance_v'): ([], []),
            ('conversation_t', 'global_t', 'utterance_t'): ([], []),
            ('conversation_a', 'global_a', 'utterance_a'): ([], []),
            ('conversation_v', 'global_v', 'utterance_v'): ([], []),
            ('utterance_t', 'emotional_link_t', 'emotion'): ([], []),
            ('utterance_a', 'emotional_link_a', 'emotion'): ([], []),
            ('utterance_v', 'emotional_link_v', 'emotion'): ([], []),
            ('utterance_t', 'causal_link_t', 'cause'): ([], []),
            ('utterance_a', 'causal_link_a', 'cause'): ([], []),
            ('utterance_v', 'causal_link_v', 'cause'): ([], []),
            ('utterance_t', 't_a', 'utterance_a'): ([], []),
            ('utterance_a', 't_a', 'utterance_t'): ([], []),
            ('utterance_t', 't_v', 'utterance_v'): ([], []),
            ('utterance_v', 't_v', 'utterance_t'): ([], []),
            ('utterance_a', 'a_v', 'utterance_v'): ([], []),
            ('utterance_v', 'a_v', 'utterance_a'): ([], []),
            ('conversation_t', 't_a', 'conversation_a'): ([], []),
            ('conversation_a', 't_a', 'conversation_t'): ([], []),
            ('conversation_t', 't_v', 'conversation_v'): ([], []),
            ('conversation_v', 't_v', 'conversation_t'): ([], []),
            ('conversation_a', 'a_v', 'conversation_v'): ([], []),
            ('conversation_v', 'a_v', 'conversation_a'): ([], []),
            
        },
    'node_types': ['conversation_t', 'conversation_a','conversation_v', 'utterance_t','utterance_a','utterance_v', 'emotion', 'cause'],
}

GRAPH_CONFIG_T = {
    'meta_paths' : [
        ['utterance', 'same_speaker', 'utterance'],
        ['utterance', 'different_speaker', 'utterance'],
        ['utterance', 'global', 'conversation'],
        ['conversation', 'global', 'utterance'],
        ['utterance', 'emotional_link', 'emotion'],
        ['utterance', 'causal_link', 'cause']
    ],
    'graph_structure': {
            ('utterance', 'global', 'conversation'): ([], []),
            ('utterance', 'same_speaker', 'utterance'): ([], []),
            ('utterance', 'different_speaker', 'utterance'): ([], []),
            ('conversation', 'global', 'utterance'): ([], []),
            ('utterance', 'emotional_link', 'emotion'): ([], []),
            ('utterance', 'causal_link', 'cause'): ([], [])
        },
    'node_types': ['conversation', 'utterance', 'emotion', 'cause'],
}